<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第12章：序列生成方法</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">3D 网格生成完整教程</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第1章：3D表示基础</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第2章：几何处理基础</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第3章：采样理论与重建基础</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第4章：Marching Cubes与体素方法</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第5章：Poisson表面重建</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第6章：基于Delaunay的重建方法</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第7章：神经隐式表示基础</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第8章：DeepSDF与Occupancy Networks</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第9章：可微分网格提取</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第10章：基于变形的网格生成</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第11章：参数化曲面方法</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第12章：序列生成方法</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第13章：3D扩散模型基础</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第14章：文本/图像驱动的3D生成</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第15章：前馈式快速生成</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter16.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第16章：多视图重建与新型表示</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">1) 经典几何重建：点云/体素 → 网格</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="12">第12章：序列生成方法</h1>
<p>序列生成方法将3D网格的生成过程视为一个离散序列的构建过程，通过自回归模型逐步生成顶点和面片。这种方法借鉴了自然语言处理中的成功经验，特别是Transformer架构在序列建模上的强大能力，为3D几何生成提供了全新的视角。本章将深入探讨PolyGen等代表性方法，分析序列化表示的设计原理，以及如何通过约束采样确保生成网格的有效性。</p>
<h2 id="121-3d">12.1 序列化3D生成概述</h2>
<h3 id="1211">12.1.1 网格作为离散序列</h3>
<p>传统的网格表示 $\mathcal{M} = (\mathcal{V}, \mathcal{F})$ 可以被重新理解为两个有序序列：</p>
<p>$$\mathcal{V} = \{v_1, v_2, ..., v_n\}, \quad v_i \in \mathbb{R}^3$$
$$\mathcal{F} = \{f_1, f_2, ..., f_m\}, \quad f_j \subseteq \{1, 2, ..., n\}$$
这种序列化视角使我们能够应用强大的序列建模技术。生成过程可以表示为条件概率分解：
$$P(\mathcal{M}|c) = P(\mathcal{V}|c) \cdot P(\mathcal{F}|\mathcal{V}, c)$$
其中 $c$ 表示条件信息（如图像、文本或类别标签）。</p>
<h3 id="1212">12.1.2 自回归建模原理</h3>
<p>自回归模型通过链式法则将联合概率分解为条件概率的乘积：
$$P(\mathcal{V}|c) = \prod_{i=1}^{n} P(v_i|v_{&lt;i}, c)$$
这种分解允许模型在生成每个元素时考虑所有先前生成的元素，确保全局一致性：</p>
<div class="codehilite"><pre><span></span><code>生成流程：

1. 初始化：h_0 = encode(c)
2. 对于 i = 1 to n：
   <span class="k">-</span> 计算上下文：h_i = attention(v_{&lt;i}, h_{i-1})
   <span class="k">-</span> 预测分布：P(v_i) = decode(h_i)
   <span class="k">-</span> 采样顶点：v_i ~ P(v_i)
</code></pre></div>

<h3 id="1213">12.1.3 优势与挑战</h3>
<p><strong>优势</strong>：</p>
<ul>
<li><strong>灵活拓扑</strong>：可生成任意亏格和连通分量的网格</li>
<li><strong>概率建模</strong>：提供明确的似然估计和不确定性量化</li>
<li><strong>条件生成</strong>：易于集成多模态条件信息</li>
<li><strong>可解释性</strong>：生成过程可逐步观察和调试</li>
</ul>
<p><strong>挑战</strong>：</p>
<ul>
<li><strong>序列长度</strong>：复杂网格的序列可能非常长（数千个token）</li>
<li><strong>排序敏感</strong>：不同的序列化顺序影响学习难度</li>
<li><strong>有效性保证</strong>：需要确保生成的面片引用有效顶点</li>
<li><strong>计算效率</strong>：自回归生成的串行特性限制推理速度</li>
</ul>
<h2 id="122-polygen">12.2 PolyGen架构详解</h2>
<h3 id="1221">12.2.1 整体架构设计</h3>
<p>PolyGen采用两阶段生成策略，分别处理顶点和面片：</p>
<div class="codehilite"><pre><span></span><code>输入图像 I
    ↓
图像编码器 (ResNet + FPN)
    ↓
全局特征 z ∈ R^d
    ├─────────────────┐
    ↓                 ↓
顶点模型           面片模型
(Vertex Model)     (Face Model)
    ↓                 ↓
顶点序列 V         面片序列 F
    └─────────────────┘
            ↓
        最终网格 M
</code></pre></div>

<h3 id="1222">12.2.2 顶点生成网络</h3>
<p>顶点模型使用Transformer解码器架构，将连续的3D坐标离散化为词表：</p>
<p><strong>坐标量化</strong>：将每个坐标轴量化为 $K$ 个离散值：
$$q(x) = \lfloor K \cdot \frac{x - x_{min}}{x_{max} - x_{min}} \rfloor$$
<strong>序列表示</strong>：每个顶点表示为3个token：
$$v_i = [x_i^q, y_i^q, z_i^q, \text{<next>}]$$
<strong>注意力机制</strong>：
$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$
其中自注意力确保新顶点与已生成顶点的空间一致性。</p>
<h3 id="1223">12.2.3 面片生成网络</h3>
<p>面片模型使用指针网络（Pointer Network）来引用已生成的顶点：</p>
<p><strong>指针机制</strong>：对于三角面片 $f = (i, j, k)$，模型预测三个指针：
$$P(i|V, f_{&lt;t}) = \text{softmax}(W_p \cdot [h_t; v_1, ..., v_n])$$
<strong>停止符预测</strong>：使用特殊token表示面片序列结束：
$$P(\text{stop}|V, F_{&lt;t}) = \sigma(W_s \cdot h_t)$$</p>
<h3 id="1224">12.2.4 训练策略</h3>
<p><strong>教师强制（Teacher Forcing）</strong>：
训练时使用真实序列作为输入，避免误差累积：
$$\mathcal{L}_{vertex} = -\sum_{i=1}^{n} \log P(v_i^*|v_{&lt;i}^*, c)$$
<strong>课程学习（Curriculum Learning）</strong>：
逐步增加生成序列的复杂度：</p>
<ul>
<li>阶段1：简单几何体（&lt; 100顶点）</li>
<li>阶段2：中等复杂度（100-500顶点）</li>
<li>阶段3：复杂网格（&gt; 500顶点）</li>
</ul>
<h2 id="123-">12.3 顶点-面序列表示</h2>
<h3 id="1231">12.3.1 网格序列化策略</h3>
<p>不同的序列化策略对学习效果有显著影响：</p>
<p><strong>广度优先遍历（BFS）</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">起始顶点</span><span class="w"> </span><span class="n">v_0</span>
<span class="n">队列</span><span class="w"> </span><span class="n">Q</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">v_0</span><span class="o">]</span>
<span class="n">序列</span><span class="w"> </span><span class="n">S</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">[]</span>
<span class="k">while</span><span class="w"> </span><span class="n">Q</span><span class="w"> </span><span class="nl">非空</span><span class="p">:</span>
<span class="w">    </span><span class="n">v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Q</span><span class="p">.</span><span class="n">dequeue</span><span class="p">()</span>
<span class="w">    </span><span class="n">S</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">邻接顶点</span><span class="w"> </span><span class="nl">u</span><span class="p">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">u</span><span class="w"> </span><span class="nl">未访问</span><span class="p">:</span>
<span class="w">            </span><span class="n">Q</span><span class="p">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
</code></pre></div>

<p><strong>基于曲率的排序</strong>：
优先访问高曲率区域，捕获几何特征：
$$\text{priority}(v) = |\kappa_1(v)| + |\kappa_2(v)|$$
<strong>空间排序</strong>：
基于空间填充曲线（如Z-order）的确定性排序：
$$\text{morton}(x, y, z) = \text{interleave}(\text{binary}(x), \text{binary}(y), \text{binary}(z))$$</p>
<h3 id="1232">12.3.2 顶点索引机制</h3>
<p>为了使面片能够正确引用顶点，需要建立稳定的索引系统：</p>
<p><strong>绝对索引</strong>：
每个顶点分配唯一ID：$v_i \rightarrow i \in \{1, 2, ..., n\}$</p>
<p><strong>相对索引</strong>：
使用相对位置减少索引空间：
$$\text{rel_idx}(v_j, \text{context}_i) = j - \max\{k | v_k \in \text{context}_i\}$$
<strong>层次索引</strong>：
多分辨率索引树，支持不同细节层次：</p>
<div class="codehilite"><pre><span></span><code>Level 0: [v1, v5, v9, ...]    # 粗糙层
Level 1: [v2, v3, v6, v7, ...] # 中等层
Level 2: [v4, v8, ...]         # 细节层
</code></pre></div>

<h3 id="1233">12.3.3 面片的序列表示</h3>
<p><strong>三角网格表示</strong>：
每个三角形表示为三个顶点索引：
$$f_i = (p_1^i, p_2^i, p_3^i), \quad p_j^i \in \{1, ..., |\mathcal{V}|\}$$
<strong>多边形网格表示</strong>：
使用变长序列和分隔符：
$$f_i = [n_i, p_1^i, ..., p_{n_i}^i, \text{<end>}]$$
其中 $n_i$ 是多边形的边数。</p>
<p><strong>面片排序策略</strong>：</p>
<ul>
<li><strong>邻接优先</strong>：按面片连通性排序，保持局部连贯性</li>
<li><strong>法向聚类</strong>：相似法向的面片grouped together</li>
<li><strong>面积加权</strong>：大面片优先，控制细节层次</li>
</ul>
<h3 id="1234">12.3.4 停止符号与边界处理</h3>
<p><strong>顶点序列终止</strong>：
$$P(\text{<stop>}|v_1, ..., v_t) = \sigma(W_{\text{stop}} \cdot h_t + b_{\text{stop}})$$
<strong>面片有效性检查</strong>：</p>
<div class="codehilite"><pre><span></span><code>def is_valid_face(face, vertices):
    # 检查索引范围
    if any(idx &gt;= len(vertices) for idx in face):
        return False
    # 检查退化情况
    if len(set(face)) &lt; 3:
        return False
    # 检查共线性
    v0, v1, v2 = vertices[face[0:3]]
    if norm(cross(v1-v0, v2-v0)) &lt; epsilon:
        return False
    return True
</code></pre></div>

<h2 id="124-transformer3d">12.4 Transformer在3D生成中的应用</h2>
<h3 id="1241">12.4.1 自注意力的几何解释</h3>
<p>在3D上下文中，注意力权重反映了空间关系：</p>
<p><strong>几何注意力</strong>：
$$\alpha_{ij} = \frac{\exp(s_{ij}/\tau)}{\sum_k \exp(s_{ik}/\tau)}$$
其中相似度结合了语义和几何信息：
$$s_{ij} = \lambda_1 \cdot \text{cosine}(h_i, h_j) + \lambda_2 \cdot \exp(-|v_i - v_j|^2/\sigma^2)$$
<strong>多头注意力的作用</strong>：</p>
<ul>
<li>Head 1-2: 局部几何关系（邻接顶点）</li>
<li>Head 3-4: 全局结构关系（对称性）</li>
<li>Head 5-6: 语义特征关系（部件级）</li>
<li>Head 7-8: 长程依赖关系（拓扑）</li>
</ul>
<h3 id="1242">12.4.2 位置编码设计</h3>
<p>标准的正弦位置编码需要适应3D几何：</p>
<p><strong>3D位置编码</strong>：
$$PE(v) = \text{concat}[PE_x(x), PE_y(y), PE_z(z)]$$
其中每个维度使用频率编码：
$$PE_x(x) = [\sin(2^0 \pi x), \cos(2^0 \pi x), ..., \sin(2^L \pi x), \cos(2^L \pi x)]$$
<strong>图结构位置编码</strong>：
基于拉普拉斯特征向量：
$$PE_{\text{graph}}(v_i) = [\phi_1(i), \phi_2(i), ..., \phi_k(i)]$$
其中 $\phi_j$ 是图拉普拉斯矩阵的第 $j$ 个特征向量。</p>
<h3 id="1243">12.4.3 条件生成机制</h3>
<p><strong>交叉注意力</strong>：
将条件信息 $c$ 融入生成过程：
$$\text{CrossAttn}(Q_{\text{mesh}}, K_{\text{cond}}, V_{\text{cond}}) = \text{softmax}\left(\frac{Q_{\text{mesh}} K_{\text{cond}}^T}{\sqrt{d}}\right) V_{\text{cond}}$$
<strong>条件嵌入</strong>：
多模态条件的统一表示：</p>
<div class="codehilite"><pre><span></span><code><span class="err">图像条件</span><span class="o">:</span><span class="w"> </span><span class="n">z_img</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CNN</span><span class="o">(</span><span class="n">I</span><span class="o">)</span>
<span class="err">文本条件</span><span class="o">:</span><span class="w"> </span><span class="n">z_text</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BERT</span><span class="o">(</span><span class="n">T</span><span class="o">)</span>
<span class="err">类别条件</span><span class="o">:</span><span class="w"> </span><span class="n">z_class</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Embed</span><span class="o">(</span><span class="n">c</span><span class="o">)</span>
<span class="err">融合</span><span class="o">:</span><span class="w"> </span><span class="n">z_cond</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MLP</span><span class="o">([</span><span class="n">z_img</span><span class="o">;</span><span class="w"> </span><span class="n">z_text</span><span class="o">;</span><span class="w"> </span><span class="n">z_class</span><span class="o">])</span>
</code></pre></div>

<h3 id="1244">12.4.4 层次化注意力机制</h3>
<p><strong>局部-全局注意力</strong>：</p>
<div class="codehilite"><pre><span></span><code>Layer 1-4: 局部窗口注意力 (window_size=32)
Layer 5-8: 稀疏全局注意力 (stride=4)
Layer 9-12: 完全注意力
</code></pre></div>

<p><strong>自适应注意力范围</strong>：
根据生成阶段动态调整：
$$\text{range}(t) = \min(t, \text{base_range} \cdot (1 + \log(1 + t/100)))$$</p>
<h2 id="125">12.5 约束采样与有效性保证</h2>
<h3 id="1251">12.5.1 几何约束的实施</h3>
<p>生成过程中必须满足的几何约束：</p>
<p><strong>非自交约束</strong>：
检测并避免面片相交：
$$\text{valid}(f_{\text{new}}) = \forall f \in \mathcal{F}: \text{intersection}(f_{\text{new}}, f) = \emptyset$$
<strong>流形约束</strong>：
确保每条边最多被两个面片共享：
$$|\{f \in \mathcal{F} : e \subset f\}| \leq 2, \quad \forall e \in \mathcal{E}$$
<strong>法向一致性</strong>：
相邻面片法向夹角约束：
$$\cos(\theta_{ij}) = \mathbf{n}_i \cdot \mathbf{n}_j &gt; \cos(\theta_{\max})$$</p>
<h3 id="1252">12.5.2 采样策略</h3>
<p><strong>Top-k采样</strong>：
限制候选集合大小：
$$\mathcal{C}_k = \text{top-k}(P(v_i|v_{&lt;i}))$$
$$v_i \sim \text{renormalize}(\mathcal{C}_k)$$
<strong>Nucleus采样（Top-p）</strong>：
动态确定候选集合：
$$\mathcal{C}_p = \{v : \sum_{v' \in \mathcal{C}_p} P(v') \leq p\}$$
<strong>温度控制</strong>：
调节生成的多样性：
$$P_{\tau}(v_i) = \frac{\exp(\text{logit}(v_i)/\tau)}{\sum_j \exp(\text{logit}(v_j)/\tau)}$$
其中：</p>
<ul>
<li>$\tau &lt; 1$: 更确定性，生成更规则</li>
<li>$\tau &gt; 1$: 更随机，生成更多样</li>
<li>$\tau = 1$: 标准采样</li>
</ul>
<h3 id="1253">12.5.3 约束引导采样</h3>
<p><strong>硬约束</strong>：
直接从有效集合中采样：
$$v_i \sim P(v_i | v_{&lt;i}, v_i \in \mathcal{V}_{\text{valid}})$$
<strong>软约束</strong>：
通过能量函数引导：
$$\tilde{P}(v_i) = P(v_i) \cdot \exp(-\lambda E(v_i, v_{&lt;i}))$$
其中能量函数定义为：
$$E(v_i, v_{&lt;i}) = w_1 E_{\text{dist}} + w_2 E_{\text{smooth}} + w_3 E_{\text{symm}}$$
<strong>梯度引导</strong>：
使用可微约束的梯度修正采样：
$$v_i' = v_i - \epsilon \nabla_{v_i} \mathcal{L}_{\text{constraint}}(v_i, v_{&lt;i})$$</p>
<h3 id="1254">12.5.4 后处理与网格修复</h3>
<p><strong>退化三角形移除</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="err">面积阈值</span><span class="o">:</span><span class="w"> </span><span class="n">A</span><span class="o">(</span><span class="n">f</span><span class="o">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="err">ε</span><span class="n">_area</span>
<span class="err">角度阈值</span><span class="o">:</span><span class="w"> </span><span class="n">min</span><span class="o">(</span><span class="n">angles</span><span class="o">(</span><span class="n">f</span><span class="o">))</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="err">ε</span><span class="n">_angle</span>
<span class="err">边长比</span><span class="o">:</span><span class="w"> </span><span class="n">max</span><span class="o">(</span><span class="n">edges</span><span class="o">)/</span><span class="n">min</span><span class="o">(</span><span class="n">edges</span><span class="o">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">ratio_max</span>
</code></pre></div>

<p><strong>拓扑修复</strong>：</p>
<ul>
<li><strong>孔洞填充</strong>：检测边界环并三角化</li>
<li><strong>非流形边修复</strong>：分裂共享超过两个面的边</li>
<li><strong>孤立组件移除</strong>：删除小于阈值的连通分量</li>
</ul>
<p><strong>网格优化</strong>：
拉普拉斯平滑：
$$v_i' = v_i + \lambda \sum_{j \in N(i)} w_{ij}(v_j - v_i)$$
其中权重 $w_{ij}$ 可以是：</p>
<ul>
<li>均匀权重：$w_{ij} = 1/|N(i)|$</li>
<li>余切权重：$w_{ij} = (\cot \alpha_{ij} + \cot \beta_{ij})/2$</li>
</ul>
<h2 id="126">12.6 扩展方法与变体</h2>
<h3 id="1261-meshgpt">12.6.1 MeshGPT与大规模预训练</h3>
<p><strong>架构改进</strong>：</p>
<ul>
<li>使用GPT-style的因果注意力</li>
<li>扩展到数十亿参数规模</li>
<li>多任务预训练（生成、补全、编辑）</li>
</ul>
<p><strong>训练策略</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="err">阶段</span><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="err">无监督预训练</span>

<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">数据</span><span class="o">:</span><span class="w"> </span><span class="err">大规模</span><span class="mi">3</span><span class="n">D数据集</span><span class="err">（</span><span class="n">Objaverse</span><span class="o">-</span><span class="n">XL</span><span class="err">）</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">任务</span><span class="o">:</span><span class="w"> </span><span class="err">网格序列的下一个</span><span class="n">token预测</span>

<span class="err">阶段</span><span class="mi">2</span><span class="o">:</span><span class="w"> </span><span class="err">监督微调</span>

<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">数据</span><span class="o">:</span><span class="w"> </span><span class="err">高质量标注数据</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">任务</span><span class="o">:</span><span class="w"> </span><span class="err">条件生成、风格迁移</span>

<span class="err">阶段</span><span class="mi">3</span><span class="o">:</span><span class="w"> </span><span class="err">强化学习微调</span>

<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">奖励</span><span class="o">:</span><span class="w"> </span><span class="err">几何质量、美学评分</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">方法</span><span class="o">:</span><span class="w"> </span><span class="n">PPO</span><span class="o">/</span><span class="n">REINFORCE</span>
</code></pre></div>

<h3 id="1262">12.6.2 基于图的序列模型</h3>
<p><strong>图序列化</strong>：
将网格视为图，使用图遍历生成序列：
$$G = (V, E) \rightarrow \text{seq} = \text{GraphTraversal}(G)$$
<strong>图注意力网络（GAT）集成</strong>：
$$h_i' = \sigma\left(\sum_{j \in N(i)} \alpha_{ij} W h_j\right)$$
其中注意力系数：
$$\alpha_{ij} = \frac{\exp(\text{LeakyReLU}(a^T[Wh_i || Wh_j]))}{\sum_{k \in N(i)} \exp(\text{LeakyReLU}(a^T[Wh_i || Wh_k]))}$$</p>
<h3 id="1263">12.6.3 混合表示的序列生成</h3>
<p><strong>隐式-显式混合</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="mf">1.</span><span class="w"> </span><span class="n">生成粗糙隐式场</span><span class="err">（</span><span class="n">SDF</span><span class="err">）</span>
<span class="mf">2.</span><span class="w"> </span><span class="n">提取初始网格</span><span class="err">（</span><span class="n">Marching</span><span class="w"> </span><span class="n">Cubes</span><span class="err">）</span>
<span class="mf">3.</span><span class="w"> </span><span class="n">序列模型细化顶点和拓扑</span>
<span class="mf">4.</span><span class="w"> </span><span class="n">最终优化和正则化</span>
</code></pre></div>

<p><strong>多模态序列</strong>：
同时生成几何、纹理和材质：
$$\text{seq} = [v_1, ..., v_n, \text{<sep>}, f_1, ..., f_m, \text{<sep>}, uv_1, ..., \text{<sep>}, \text{material}]$$
<strong>层次化序列生成</strong>：</p>
<div class="codehilite"><pre><span></span><code>Level 0: 生成包围盒顶点（8个）
Level 1: 细分并生成主要特征（~50个顶点）
Level 2: 添加细节（~200个顶点）
Level 3: 最终细化（~1000个顶点）
</code></pre></div>

<p>每层使用不同的模型和词表精度。</p>
<h2 id="_1">本章小结</h2>
<p>序列生成方法为3D网格生成开辟了新的范式，通过将连续的几何结构离散化为符号序列，使得我们能够利用自然语言处理领域的强大模型架构。关键要点包括：</p>
<ol>
<li>
<p><strong>序列化表示</strong>：网格的顶点-面序列表示使得自回归建模成为可能，不同的序列化策略（BFS、空间排序、曲率优先）对学习效果有显著影响。</p>
</li>
<li>
<p><strong>PolyGen架构</strong>：两阶段生成（顶点→面片）有效分离了几何和拓扑的复杂性，指针网络巧妙解决了面片引用问题。</p>
</li>
<li>
<p><strong>Transformer的应用</strong>：自注意力机制天然适合捕获3D空间关系，位置编码和条件机制的设计对生成质量至关重要。</p>
</li>
<li>
<p><strong>约束与采样</strong>：通过硬约束、软约束和后处理确保生成网格的有效性，温度控制和nucleus采样平衡了质量与多样性。</p>
</li>
<li>
<p><strong>扩展方向</strong>：大规模预训练（MeshGPT）、图序列模型、混合表示等方法展示了序列生成的广阔前景。</p>
</li>
</ol>
<p>关键公式回顾：</p>
<ul>
<li>自回归分解：$P(\mathcal{M}) = P(\mathcal{V}) \cdot P(\mathcal{F}|\mathcal{V})$</li>
<li>几何注意力：$\alpha_{ij} = \text{softmax}(s_{ij}/\tau)$</li>
<li>约束采样：$\tilde{P}(v) = P(v) \cdot \exp(-\lambda E(v))$</li>
</ul>
<h2 id="gotchas">常见陷阱与错误（Gotchas）</h2>
<h3 id="1">1. 序列长度爆炸</h3>
<p><strong>问题</strong>：复杂网格可能产生数千个token的序列，导致训练和推理效率低下。
<strong>解决</strong>：</p>
<ul>
<li>使用层次化生成，先生成粗糙网格再细化</li>
<li>采用稀疏注意力机制减少计算复杂度</li>
<li>实施序列长度上限和自适应截断</li>
</ul>
<h3 id="2">2. 顶点排序依赖</h3>
<p><strong>问题</strong>：模型性能对顶点序列化顺序高度敏感。
<strong>解决</strong>：</p>
<ul>
<li>训练时使用多种排序的数据增强</li>
<li>设计排序不变的架构（如使用Set2Seq）</li>
<li>采用确定性的规范化排序（如Morton编码）</li>
</ul>
<h3 id="3">3. 面片有效性违反</h3>
<p><strong>问题</strong>：生成的面片可能引用不存在的顶点索引。
<strong>解决</strong>：</p>
<ul>
<li>使用masked attention确保只能引用已生成顶点</li>
<li>实施运行时验证和回退机制</li>
<li>训练时加入有效性奖励的强化学习</li>
</ul>
<h3 id="4">4. 拓扑不一致</h3>
<p><strong>问题</strong>：生成的网格可能包含非流形结构、自相交等拓扑错误。
<strong>调试技巧</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="mf">1.</span><span class="w"> </span><span class="n">检查每条边的面片数</span><span class="err">（</span><span class="n">应该</span><span class="err">≤</span><span class="mf">2</span><span class="err">）</span>
<span class="mf">2.</span><span class="w"> </span><span class="n">验证欧拉特征数</span><span class="err">：</span><span class="n">V</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">E</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">F</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2</span><span class="p">(</span><span class="mf">1</span><span class="o">-</span><span class="n">g</span><span class="p">)</span>
<span class="mf">3.</span><span class="w"> </span><span class="n">使用半边结构验证局部拓扑</span>
<span class="mf">4.</span><span class="w"> </span><span class="n">可视化法向量检测翻转面片</span>
</code></pre></div>

<h3 id="5">5. 训练不稳定</h3>
<p><strong>问题</strong>：序列模型训练容易出现梯度爆炸或模式崩塌。
<strong>解决</strong>：</p>
<ul>
<li>使用梯度裁剪（clip_norm=1.0）</li>
<li>采用warmup学习率调度</li>
<li>实施teacher forcing比例的课程学习</li>
<li>监控perplexity和生成质量指标</li>
</ul>
<h3 id="6-">6. 采样-训练不匹配</h3>
<p><strong>问题</strong>：训练时使用teacher forcing，推理时自回归采样，导致误差累积。
<strong>解决</strong>：</p>
<ul>
<li>Scheduled sampling：逐渐增加模型预测的使用比例</li>
<li>使用生成样本进行自训练</li>
<li>引入噪声注入提高鲁棒性</li>
</ul>
<h3 id="7">7. 条件信息泄露</h3>
<p><strong>问题</strong>：模型可能过度依赖条件信息，忽略序列上下文。
<strong>调试方法</strong>：</p>
<ul>
<li>随机mask部分条件信息进行训练</li>
<li>分析注意力权重分布</li>
<li>测试zero-shot生成能力</li>
</ul>
<h2 id="_2">练习题</h2>
<h3 id="1_1">练习1：序列化策略比较（基础题）</h3>
<p>给定一个简单的四面体网格，顶点为 $v_1=(0,0,0)$, $v_2=(1,0,0)$, $v_3=(0,1,0)$, $v_4=(0,0,1)$，分别使用BFS遍历和Morton编码生成顶点序列，并分析两种序列的特点。</p>
<p><strong>Hint</strong>: BFS从任意顶点开始，按邻接关系遍历；Morton编码需要先将坐标归一化到[0,1]区间。</p>
<details>
<summary>答案</summary>
<p><strong>BFS序列</strong>（从$v_1$开始）：</p>
<ul>
<li>序列：$[v_1, v_2, v_3, v_4]$</li>
<li>特点：保持局部连通性，相邻顶点在序列中位置接近</li>
</ul>
<p><strong>Morton编码序列</strong>：</p>
<ol>
<li>归一化坐标：$v_1=(0,0,0)$, $v_2=(1,0,0)$, $v_3=(0,1,0)$, $v_4=(0,0,1)$</li>
<li>Morton码：$v_1=000_2=0$, $v_2=100_2=4$, $v_3=010_2=2$, $v_4=001_2=1$</li>
<li>排序序列：$[v_1, v_4, v_3, v_2]$</li>
<li>特点：空间局部性好，适合并行处理，但可能破坏网格连通性</li>
</ol>
<p>BFS更适合保持拓扑结构，Morton编码更适合空间查询和分层处理。</p>
</details>
<h3 id="2_1">练习2：注意力权重分析（基础题）</h3>
<p>在生成第5个顶点时，自注意力机制产生了权重$[\alpha_1, \alpha_2, \alpha_3, \alpha_4] = [0.1, 0.15, 0.35, 0.4]$。如果前4个顶点形成了一个平面四边形，这个权重分布说明了什么？第5个顶点最可能的位置是什么？</p>
<p><strong>Hint</strong>: 考虑权重最高的顶点对新顶点位置的影响。</p>
<details>
<summary>答案</summary>
<p>权重分布表明：</p>
<ul>
<li>第5个顶点主要受$v_3$（权重0.35）和$v_4$（权重0.4）影响</li>
<li>$v_1$和$v_2$的影响较小（权重0.1和0.15）</li>
</ul>
<p>这暗示：</p>
<ol>
<li>第5个顶点在空间上更接近$v_3$和$v_4$</li>
<li>可能形成一个三角形面片$(v_3, v_4, v_5)$</li>
<li>如果四边形是矩形ABCD（$v_1=A, v_2=B, v_3=C, v_4=D$），第5个顶点可能在CD边的上方，形成金字塔或棱柱的开始</li>
</ol>
<p>这种注意力模式体现了局部几何一致性的学习。</p>
</details>
<h3 id="3_1">练习3：温度参数影响（基础题）</h3>
<p>给定顶点预测的原始logits为$[2.0, 1.5, 1.0, 0.5, 0.0]$，计算温度$\tau=0.5$和$\tau=2.0$时的概率分布，并解释温度对生成的影响。</p>
<p><strong>Hint</strong>: 使用公式$P_i = \exp(\text{logit}_i/\tau) / \sum_j \exp(\text{logit}_j/\tau)$</p>
<details>
<summary>答案</summary>
<p><strong>$\tau = 0.5$（低温）</strong>：</p>
<ul>
<li>缩放后logits: $[4.0, 3.0, 2.0, 1.0, 0.0]$</li>
<li>概率: $[0.516, 0.283, 0.155, 0.042, 0.004]$</li>
<li>特点：分布更尖锐，倾向选择高概率选项，生成更确定、规则</li>
</ul>
<p><strong>$\tau = 2.0$（高温）</strong>：</p>
<ul>
<li>缩放后logits: $[1.0, 0.75, 0.5, 0.25, 0.0]$</li>
<li>概率: $[0.299, 0.244, 0.199, 0.162, 0.096]$</li>
<li>特点：分布更平坦，增加多样性，可能产生更创新但也更不规则的结果</li>
</ul>
<p>低温适合生成规则几何体，高温适合探索新颖形状。</p>
</details>
<h3 id="4_1">练习4：面片指针网络（挑战题）</h3>
<p>设计一个指针网络的注意力机制，使其能够避免生成退化三角形（三点共线）。给出数学形式并解释如何集成到PolyGen架构中。</p>
<p><strong>Hint</strong>: 考虑在注意力计算中加入几何约束项。</p>
<details>
<summary>答案</summary>
<p>设计带几何约束的指针注意力：
$$\alpha_{ijk} = \frac{\exp(s_{ijk} + \lambda g_{ijk})}{\sum_{i',j',k'} \exp(s_{i'j'k'} + \lambda g_{i'j'k'})}$$
其中几何约束项：
$$g_{ijk} = \begin{cases}
\log(|(\mathbf{v}_j - \mathbf{v}_i) \times (\mathbf{v}_k - \mathbf{v}_i)|) &amp; \text{if } |·| &gt; \epsilon \\
-\infty &amp; \text{otherwise}
\end{cases}$$
集成到PolyGen：</p>
<ol>
<li>
<p>在Face Model的每个指针预测步骤中：
   - 第一个指针$p_1$：标准注意力
   - 第二个指针$p_2$：排除$p_1$
   - 第三个指针$p_3$：使用上述几何约束注意力</p>
</li>
<li>
<p>训练时梯度：
$$\nabla_\theta \mathcal{L} = \nabla_\theta \mathcal{L}_{\text{CE}} + \beta \nabla_\theta \mathcal{L}_{\text{geom}}$$
其中$\mathcal{L}_{\text{geom}}$惩罚接近退化的三角形。</p>
</li>
<li>
<p>推理时使用beam search，剪枝几何无效的候选。</p>
</li>
</ol>
</details>
<h3 id="5_1">练习5：序列长度优化（挑战题）</h3>
<p>推导层次化生成相对于直接生成的计算复杂度改进。假设最终网格有$N$个顶点，使用$L$层层次结构，每层细化因子为$r$。</p>
<p><strong>Hint</strong>: 考虑自注意力的$O(n^2)$复杂度。</p>
<details>
<summary>答案</summary>
<p><strong>直接生成复杂度</strong>：</p>
<ul>
<li>序列长度：$N$</li>
<li>自注意力复杂度：$O(N^2)$</li>
<li>总复杂度：$O(N^2 \cdot d)$，其中$d$是特征维度</li>
</ul>
<p><strong>层次化生成复杂度</strong>：
设第$l$层有$N_l$个顶点，满足$N_l = N_0 \cdot r^l$，且$N_L = N$。</p>
<p>因此$N_0 = N/r^L$，每层复杂度：
$$C_l = O(N_l^2) = O((N_0 \cdot r^l)^2)$$
总复杂度：
$$C_{\text{total}} = \sum_{l=0}^{L} C_l = O(N_0^2) \sum_{l=0}^{L} r^{2l} = O(N_0^2 \cdot \frac{r^{2(L+1)}-1}{r^2-1})$$
当$r=2$，$L=\log_2(N/N_0)$时：
$$C_{\text{total}} = O(N_0^2 \cdot \frac{4N^2/N_0^2 - 1}{3}) \approx O(\frac{4N^2}{3})$$
但由于每层独立，实际改进来自于：</p>
<ol>
<li>每层可并行训练</li>
<li>早期层误差不会传播</li>
<li>内存需求从$O(N^2)$降至$O(\max_l N_l^2) = O((N/r^{L-1})^2)$</li>
</ol>
<p><strong>结论</strong>：层次化将空间复杂度降低$r^{2(L-1)}$倍，时间上支持并行。</p>
</details>
<h3 id="6">练习6：拓扑一致性验证（挑战题）</h3>
<p>给定一个生成的网格序列，设计一个算法验证其是否满足2-流形条件。算法应该能检测：(a) 非流形边，(b) 非流形顶点，(c) 边界一致性。</p>
<p><strong>Hint</strong>: 2-流形的每条边最多被两个面共享，每个顶点的邻域同胚于圆盘或半圆盘。</p>
<details>
<summary>答案</summary>
<div class="codehilite"><pre><span></span><code><span class="n">算法</span><span class="err">：</span><span class="mi">2</span><span class="o">-</span><span class="n">流形验证</span>

<span class="n">输入</span><span class="err">：</span><span class="n">顶点列表V</span><span class="err">，</span><span class="n">面片列表F</span>
<span class="n">输出</span><span class="err">：</span><span class="n">是否为2</span><span class="o">-</span><span class="n">流形</span><span class="err">，</span><span class="n">错误列表</span>

<span class="mf">1.</span><span class="w"> </span><span class="n">构建边</span><span class="o">-</span><span class="n">面邻接表</span><span class="err">：</span>
<span class="w">   </span><span class="n">edge_faces</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{}</span>
<span class="w">   </span><span class="k">for</span><span class="w"> </span><span class="n">face</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nl">F</span><span class="p">:</span>
<span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">edge</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">face</span><span class="p">.</span><span class="n">edges</span><span class="p">()</span><span class="err">:</span>
<span class="w">           </span><span class="n">edge_faces</span><span class="o">[</span><span class="n">edge</span><span class="o">]</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">face</span><span class="p">)</span>

<span class="mf">2.</span><span class="w"> </span><span class="n">检测非流形边</span><span class="err">：</span>
<span class="w">   </span><span class="k">for</span><span class="w"> </span><span class="n">edge</span><span class="p">,</span><span class="w"> </span><span class="n">faces</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nl">edge_faces</span><span class="p">:</span>
<span class="w">       </span><span class="k">if</span><span class="w"> </span><span class="nf">len</span><span class="p">(</span><span class="n">faces</span><span class="p">)</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">2</span><span class="err">:</span>
<span class="w">           </span><span class="n">errors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="ss">&quot;非流形边 {edge}: {len(faces)} 个面&quot;</span><span class="p">)</span>
<span class="w">       </span><span class="k">if</span><span class="w"> </span><span class="nf">len</span><span class="p">(</span><span class="n">faces</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="err">:</span>
<span class="w">           </span><span class="n">boundary_edges</span><span class="p">.</span><span class="k">add</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>

<span class="mf">3.</span><span class="w"> </span><span class="n">检测非流形顶点</span><span class="err">：</span>
<span class="w">   </span><span class="k">for</span><span class="w"> </span><span class="n">vertex</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nl">V</span><span class="p">:</span>
<span class="w">       </span><span class="err">#</span><span class="w"> </span><span class="n">获取顶点的1</span><span class="o">-</span><span class="n">邻域</span>
<span class="w">       </span><span class="n">incident_faces</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_incident_faces</span><span class="p">(</span><span class="n">vertex</span><span class="p">)</span>
<span class="w">       </span><span class="n">incident_edges</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_incident_edges</span><span class="p">(</span><span class="n">vertex</span><span class="p">)</span>

<span class="w">       </span><span class="err">#</span><span class="w"> </span><span class="n">构建局部图</span>
<span class="w">       </span><span class="n">local_graph</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">build_local_graph</span><span class="p">(</span><span class="n">incident_faces</span><span class="p">)</span>

<span class="w">       </span><span class="err">#</span><span class="w"> </span><span class="n">检查连通性</span>
<span class="w">       </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">is_connected</span><span class="p">(</span><span class="n">local_graph</span><span class="p">)</span><span class="err">:</span>
<span class="w">           </span><span class="n">errors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="ss">&quot;非流形顶点 {vertex}: 邻域不连通&quot;</span><span class="p">)</span>

<span class="w">       </span><span class="err">#</span><span class="w"> </span><span class="n">检查欧拉特征</span>
<span class="w">       </span><span class="n">V_local</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">len</span><span class="p">(</span><span class="n">get_local_vertices</span><span class="p">(</span><span class="n">vertex</span><span class="p">))</span>
<span class="w">       </span><span class="n">E_local</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">len</span><span class="p">(</span><span class="n">incident_edges</span><span class="p">)</span>
<span class="w">       </span><span class="n">F_local</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">len</span><span class="p">(</span><span class="n">incident_faces</span><span class="p">)</span>

<span class="w">       </span><span class="k">if</span><span class="w"> </span><span class="n">vertex</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nl">boundary</span><span class="p">:</span>
<span class="w">           </span><span class="err">#</span><span class="w"> </span><span class="n">边界顶点</span><span class="err">：</span><span class="n">χ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="err">（</span><span class="n">半圆盘</span><span class="err">）</span>
<span class="w">           </span><span class="k">if</span><span class="w"> </span><span class="n">V_local</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">E_local</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">F_local</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">1</span><span class="err">:</span>
<span class="w">               </span><span class="n">errors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="ss">&quot;边界顶点 {vertex} 拓扑错误&quot;</span><span class="p">)</span>
<span class="w">       </span><span class="k">else</span><span class="err">:</span>
<span class="w">           </span><span class="err">#</span><span class="w"> </span><span class="n">内部顶点</span><span class="err">：</span><span class="n">χ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="err">（</span><span class="n">圆盘</span><span class="err">）</span>
<span class="w">           </span><span class="k">if</span><span class="w"> </span><span class="n">V_local</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">E_local</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">F_local</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">1</span><span class="err">:</span>
<span class="w">               </span><span class="n">errors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="ss">&quot;内部顶点 {vertex} 拓扑错误&quot;</span><span class="p">)</span>

<span class="mf">4.</span><span class="w"> </span><span class="n">验证边界一致性</span><span class="err">：</span>
<span class="w">   </span><span class="err">#</span><span class="w"> </span><span class="n">边界应形成闭合环</span>
<span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">form_closed_loops</span><span class="p">(</span><span class="n">boundary_edges</span><span class="p">)</span><span class="err">:</span>
<span class="w">       </span><span class="n">errors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="ss">&quot;边界不形成闭合环&quot;</span><span class="p">)</span>

<span class="n">返回</span><span class="w"> </span><span class="nf">len</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">errors</span>
</code></pre></div>

<p>关键检查：</p>
<ul>
<li>边的面片数≤2</li>
<li>顶点邻域的连通性</li>
<li>局部欧拉特征数</li>
<li>边界形成简单闭合曲线</li>
</ul>
</details>
<h3 id="7_1">练习7：条件生成的信息流（开放题）</h3>
<p>分析PolyGen中条件信息（如输入图像）如何影响最终生成的网格。设计实验验证条件信息在不同生成阶段的重要性。</p>
<p><strong>Hint</strong>: 考虑注意力权重可视化、梯度分析、ablation study。</p>
<details>
<summary>答案</summary>
<p><strong>信息流分析</strong>：</p>
<ol>
<li>
<p><strong>编码阶段</strong>：
   - 图像通过CNN提取特征$z_{\text{img}} \in \mathbb{R}^d$
   - 特征通过交叉注意力影响每个生成步骤</p>
</li>
<li>
<p><strong>顶点生成阶段</strong>：
   - 早期顶点（轮廓）：高度依赖图像全局特征
   - 中期顶点（主要结构）：平衡图像特征和已生成顶点
   - 后期顶点（细节）：主要依赖局部一致性</p>
</li>
<li>
<p><strong>面片生成阶段</strong>：
   - 条件信息主要通过顶点间接影响
   - 直接影响较小（主要是拓扑先验）</p>
</li>
</ol>
<p><strong>实验设计</strong>：</p>
<ol>
<li>
<p><strong>注意力分析实验</strong>：
   - 记录每步的交叉注意力权重
   - 绘制权重随时间的变化曲线
   - 预期：早期权重高，后期递减</p>
</li>
<li>
<p><strong>条件mask实验</strong>：
   - 在不同阶段mask条件信息
   - 测量生成质量下降程度
   - 量化指标：Chamfer距离、法向一致性</p>
</li>
<li>
<p><strong>梯度归因实验</strong>：
   - 计算$\nabla_{z_{\text{img}}} \mathcal{L}_{\text{vertex}}(t)$
   - 分析梯度范数随$t$的变化
   - 识别关键决策点</p>
</li>
<li>
<p><strong>条件插值实验</strong>：
   - 在条件空间插值：$z_{\alpha} = \alpha z_1 + (1-\alpha) z_2$
   - 观察生成结果的连续变化
   - 验证语义的平滑过渡</p>
</li>
</ol>
<p><strong>预期发现</strong>：</p>
<ul>
<li>粗糙几何主要由条件决定（前30%步骤）</li>
<li>细节由局部一致性主导（后40%步骤）</li>
<li>存在关键转折点需要特别关注</li>
</ul>
</details>
<h3 id="84d">练习8：扩展到4D网格（开放题）</h3>
<p>探讨如何将PolyGen架构扩展到生成4D网格（如时空网格或4D几何）。讨论主要挑战和可能的解决方案。</p>
<p><strong>Hint</strong>: 考虑4D单纯形、时序一致性、计算复杂度。</p>
<details>
<summary>答案</summary>
<p><strong>4D网格表示</strong>：</p>
<ul>
<li>顶点：$v_i \in \mathbb{R}^4$ (x, y, z, t)</li>
<li>4-单纯形：5个顶点构成的超四面体</li>
<li>边界：3-单纯形（四面体）</li>
</ul>
<p><strong>架构扩展</strong>：</p>
<ol>
<li>
<p><strong>序列表示</strong>：
   - 顶点：4个坐标token + 分隔符
   - 4-单纯形：5个顶点索引
   - 序列长度显著增加</p>
</li>
<li>
<p><strong>位置编码</strong>：
$$PE_{4D}(v) = [PE_x(x), PE_y(y), PE_z(z), PE_t(t)]$$
时间维度可能需要特殊处理（周期性或单调性）</p>
</li>
<li>
<p><strong>注意力机制</strong>：
   - 空间注意力：$(x,y,z)$维度
   - 时间注意力：$t$维度
   - 时空交叉注意力</p>
</li>
</ol>
<p><strong>主要挑战</strong>：</p>
<ol>
<li>
<p><strong>组合爆炸</strong>：
   - 4-单纯形数量急剧增加
   - 序列长度可能达到$O(N^{4/3})$</p>
</li>
<li>
<p><strong>可视化困难</strong>：
   - 无法直接可视化4D结构
   - 需要切片或投影技术</p>
</li>
<li>
<p><strong>拓扑复杂性</strong>：
   - 4D拓扑不变量更复杂
   - 难以验证有效性</p>
</li>
</ol>
<p><strong>解决方案</strong>：</p>
<ol>
<li><strong>层次化生成</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code>Level 0: 关键帧（3D切片）
Level 1: 帧间插值
Level 2: 时空细化
</code></pre></div>

<ol start="2">
<li>
<p><strong>因子分解</strong>：
$$P(M_{4D}) = P(M_{3D}^{t_0}) \prod_t P(M_{3D}^t | M_{3D}^{&lt;t})$$</p>
</li>
<li>
<p><strong>约束简化</strong>：
   - 限制为产品空间：$\mathbb{R}^3 \times \mathbb{R}$
   - 使用3D+1D的特殊结构</p>
</li>
<li>
<p><strong>专门的4D操作</strong>：
   - 4D Delaunay三角化
   - 超体素marching
   - 4D拉普拉斯算子</p>
</li>
</ol>
<p><strong>应用场景</strong>：</p>
<ul>
<li>动态网格序列（3D+时间）</li>
<li>高维数据可视化</li>
<li>时空物理模拟</li>
<li>4D打印路径规划
</details></li>
</ul>
</details>
            </article>
            
            <nav class="page-nav"><a href="chapter11.html" class="nav-link prev">← 第11章：参数化曲面方法</a><a href="chapter13.html" class="nav-link next">第13章：3D扩散模型基础 →</a></nav>
        </main>
    </div>
</body>
</html>